{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koog A2A Server Notebook\n",
    "\n",
    "This notebook demonstrates how to set up and run an Agent-to-Agent (A2A) server using the Koog library. The server exposes an AI agent that can generate jokes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dependencies\n",
    "\n",
    "This cell declares the necessary dependencies for the A2A server. It includes libraries for the Koog agents, the A2A server features, and the HTTP JSON-RPC transport."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:46:08.811842Z",
     "start_time": "2025-11-01T12:46:08.779537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// show kernel version\n",
    "\"\"\"\n",
    "Kotlin Jupyter kernel version: ${notebook.kernelVersion} (Update in Settings > Tools > Kotlin Notebooks > Kernel version)\n",
    "Java Runtime Environment version: ${notebook.jreInfo.javaVersion}\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Kotlin Jupyter kernel version: 0.15.2.706.dev1 (Update in Settings > Tools > Kotlin Notebooks > Kernel version)\n",
       "Java Runtime Environment version: 21\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:44:13.650347Z",
     "start_time": "2025-11-01T12:44:13.206430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE {\n",
    "    repositories {\n",
    "        mavenCentral()\n",
    "    }\n",
    "    dependencies {\n",
    "        implementation(\"ai.koog:koog-agents-jvm:0.5.2\")\n",
    "        implementation(\"ai.koog:agents-features-a2a-server-jvm:0.5.2\")\n",
    "        implementation(\"ai.koog:a2a-server-jvm:0.5.2\")\n",
    "        implementation(\"ai.koog:a2a-transport-server-jsonrpc-http-jvm:0.5.2\")\n",
    "    }\n",
    "}\n",
    "notebook.dependencyManager.currentBinaryClasspath.map { it.toPath().fileName }.joinToString(\"\\n\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lib-0.15.2-706-1.jar\n",
       "protocol-api-0.15.2-706-1.jar\n",
       "kotlin-reflect-2.2.20.jar\n",
       "api-0.15.2-706-1.jar\n",
       "annotations-13.0.jar\n",
       "kotlinx-serialization-json-jvm-1.9.0.jar\n",
       "kotlin-stdlib-2.2.20.jar\n",
       "kotlin-script-runtime-2.2.20.jar\n",
       "slf4j-api-2.0.17.jar\n",
       "kotlinx-serialization-core-jvm-1.9.0.jar"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:23:59.002580Z",
     "start_time": "2025-11-01T12:23:58.933960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ai.koog.a2a.exceptions.A2AUnsupportedOperationException\n",
    "import ai.koog.a2a.model.APIKeySecurityScheme\n",
    "import ai.koog.a2a.model.AgentCapabilities\n",
    "import ai.koog.a2a.model.MessageSendParams\n",
    "import ai.koog.a2a.model.Role\n",
    "import ai.koog.a2a.model.TaskIdParams\n",
    "import ai.koog.a2a.model.TaskState\n",
    "import ai.koog.a2a.model.TaskStatus\n",
    "import ai.koog.a2a.model.TaskStatusUpdateEvent\n",
    "import ai.koog.a2a.model.TextPart\n",
    "import ai.koog.a2a.server.A2AServer\n",
    "import ai.koog.a2a.server.agent.AgentExecutor\n",
    "import ai.koog.a2a.server.session.RequestContext\n",
    "import ai.koog.a2a.server.session.SessionEventProcessor\n",
    "import ai.koog.a2a.model.AgentCard\n",
    "import ai.koog.a2a.model.AgentInterface\n",
    "import ai.koog.a2a.model.AgentProvider\n",
    "import ai.koog.a2a.model.AgentSkill\n",
    "import ai.koog.a2a.model.HTTPAuthSecurityScheme\n",
    "import ai.koog.a2a.model.In\n",
    "import ai.koog.a2a.model.Task\n",
    "import ai.koog.a2a.model.TransportProtocol\n",
    "import ai.koog.a2a.transport.server.jsonrpc.http.HttpJSONRPCServerTransport\n",
    "import ai.koog.agents.a2a.core.A2AMessage\n",
    "import ai.koog.agents.a2a.core.MessageA2AMetadata\n",
    "import ai.koog.agents.a2a.core.toA2AMessage\n",
    "import ai.koog.agents.a2a.core.toKoogMessage\n",
    "import ai.koog.agents.a2a.server.feature.A2AAgentServer\n",
    "import ai.koog.agents.core.agent.AIAgent\n",
    "import ai.koog.agents.core.agent.config.AIAgentConfig\n",
    "import ai.koog.agents.core.dsl.builder.strategy\n",
    "import ai.koog.agents.core.tools.ToolRegistry\n",
    "import ai.koog.prompt.dsl.prompt\n",
    "import ai.koog.prompt.executor.clients.openai.OpenAIClientSettings\n",
    "import ai.koog.prompt.executor.clients.openai.OpenAILLMClient\n",
    "import ai.koog.prompt.executor.clients.openai.OpenAIModels\n",
    "import ai.koog.prompt.executor.llms.SingleLLMPromptExecutor\n",
    "import ai.koog.prompt.llm.LLMCapability\n",
    "import ai.koog.prompt.llm.LLMProvider\n",
    "import ai.koog.prompt.llm.LLModel\n",
    "import ai.koog.prompt.message.Message\n",
    "import io.ktor.server.cio.CIO\n",
    "import kotlinx.coroutines.Deferred\n",
    "import kotlinx.coroutines.Dispatchers\n",
    "import kotlinx.coroutines.runBlocking\n",
    "import kotlinx.coroutines.delay\n",
    "import kotlinx.datetime.Clock\n",
    "import java.util.UUID\n",
    "import kotlin.uuid.ExperimentalUuidApi\n",
    "import kotlin.uuid.Uuid"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agent Creation\n",
    "\n",
    "This cell defines the AI agent that will power our A2A server. The `createAgent` function configures and returns an `AIAgent` instance.\n",
    "\n",
    "The agent uses a `SingleLLMPromptExecutor` with an `OpenAILLMClient`. This means it will use an OpenAI-compatible LLM to generate responses.\n",
    "\n",
    "The `apiToken` is a placeholder and the `OpenAIClientSettings` point to a local LLM server. The follow example is using local LM studio to host `openai/gpt-oss-20b` model."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:23:59.168465Z",
     "start_time": "2025-11-01T12:23:59.005719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Define the LLM model to be used by the agent\n",
    "// You can install https://lmstudio.ai/ and run local model in your machine\n",
    "val model = LLModel(\n",
    "    provider = LLMProvider.OpenAI,\n",
    "    id = \"openai/gpt-oss-20b\",\n",
    "    capabilities = listOf(\n",
    "        LLMCapability.Tools,\n",
    "        LLMCapability.ToolChoice,\n",
    "        LLMCapability.Speculation,\n",
    "        LLMCapability.Schema.JSON.Basic,\n",
    "        LLMCapability.Schema.JSON.Standard,\n",
    "        LLMCapability.Document,\n",
    "        LLMCapability.Completion,\n",
    "        LLMCapability.MultipleChoices,\n",
    "        LLMCapability.OpenAIEndpoint.Completions,\n",
    "        LLMCapability.OpenAIEndpoint.Responses,\n",
    "    ),\n",
    "    contextLength = 128_000,\n",
    "    maxOutputTokens = 8_000,\n",
    ")\n",
    "\n",
    "// Function to create a new AI agent\n",
    "fun createAgent(): AIAgent<String, String> = AIAgent(\n",
    "    promptExecutor = SingleLLMPromptExecutor(\n",
    "        OpenAILLMClient(\n",
    "            \"apiToken\", // Placeholder API token\n",
    "            OpenAIClientSettings(\"http://localhost:1234/\") // URL of the local LM Studio server\n",
    "        )\n",
    "    ),\n",
    "    systemPrompt = \"You are an assistant helping user to generate jokes\", // System prompt for the agent\n",
    "    llmModel = model,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Agent Executor\n",
    "\n",
    "The `AgentExecutor` is the core component that handles incoming requests and interacts with the AI agent. The `SimpleJokeAgentExecutor` class implements the `AgentExecutor` interface.\n",
    "\n",
    "In the `execute` method, it performs the following steps:\n",
    "1. Retrieves the user's message from the request context.\n",
    "2. Saves the incoming message to the message storage.\n",
    "3. Loads the conversation history.\n",
    "4. Creates a prompt with the conversation history.\n",
    "5. Calls the AI agent to get a response.\n",
    "6. Saves the agent's response to the message storage.\n",
    "7. Sends the response back to the client."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:23:59.499345Z",
     "start_time": "2025-11-01T12:23:59.172763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleJokeAgentExecutor : AgentExecutor {\n",
    "    @OptIn(ExperimentalUuidApi::class)\n",
    "    override suspend fun execute(context: RequestContext<MessageSendParams>, eventProcessor: SessionEventProcessor) {\n",
    "        val userMessage = context.params.message\n",
    "\n",
    "        if (context.task != null || !userMessage.referenceTaskIds.isNullOrEmpty()) {\n",
    "            throw A2AUnsupportedOperationException(\"This agent doesn't support tasks\")\n",
    "        }\n",
    "\n",
    "        // Save incoming message to the current context\n",
    "        context.messageStorage.save(userMessage)\n",
    "\n",
    "        // Load all messages from the current context\n",
    "        val contextMessages = context.messageStorage.getAll().map { it.toKoogMessage() }\n",
    "\n",
    "        val prompt = prompt(\"\") {\n",
    "            // Append current message context\n",
    "            messages(contextMessages)\n",
    "        }\n",
    "\n",
    "        // Get a response from the LLM\n",
    "        val responseMessage = createAgent().run(prompt.toString())\n",
    "            .let {\n",
    "                ai.koog.agents.a2a.core.A2AMessage(\n",
    "                    role = Role.Agent,\n",
    "                    messageId = Uuid.random().toString(),\n",
    "                    contextId = context.contextId,\n",
    "                    parts = listOf(TextPart(it)),\n",
    "                )\n",
    "            }\n",
    "\n",
    "        // Save the response to the current context\n",
    "        context.messageStorage.save(responseMessage)\n",
    "\n",
    "        // Reply with message\n",
    "        eventProcessor.sendMessage(responseMessage)\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Card\n",
    "\n",
    "The `AgentCard` provides metadata about the agent to other agents and clients. It includes information like the agent's name, description, communication settings, capabilities, and skills.\n",
    "\n",
    "This agent card defines the following:\n",
    "- **Basic Identity**: Name, description, and version.\n",
    "- **Communication Settings**: The server URL and preferred transport protocol.\n",
    "- **Capabilities**: Streaming, push notifications, and state transition history.\n",
    "- **Content Type Support**: Supported input and output MIME types.\n",
    "- **Skills**: A list of skills the agent possesses, in this case, `joke-generation`."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:23:59.613145Z",
     "start_time": "2025-11-01T12:23:59.503618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val agentCard = AgentCard(\n",
    "    // Basic Identity\n",
    "    name = \"Joke maker\",\n",
    "    description = \"AI agent specialized in telling joke\",\n",
    "    version = \"2.1.0\",\n",
    "    protocolVersion = \"0.3.0\",\n",
    "\n",
    "    // Communication Settings\n",
    "    url = \"http://localhost:9000/a2a\",\n",
    "    preferredTransport = TransportProtocol.JSONRPC,\n",
    "\n",
    "    // Capabilities Declaration\n",
    "    capabilities = AgentCapabilities(\n",
    "        streaming = true,              // Support real-time responses\n",
    "        pushNotifications = true,      // Send async notifications\n",
    "        stateTransitionHistory = true  // Maintain task history\n",
    "    ),\n",
    "\n",
    "    // Content Type Support\n",
    "    defaultInputModes = listOf(\"text/plain\", \"text/markdown\", \"image/jpeg\"),\n",
    "    defaultOutputModes = listOf(\"text/plain\", \"text/markdown\", \"application/json\"),\n",
    "\n",
    "    // Define available security schemes\n",
    "    securitySchemes = mapOf(),\n",
    "\n",
    "    // Specify security requirements (logical OR of requirements)\n",
    "    security = listOf(),\n",
    "\n",
    "    // Enable extended card for authenticated users\n",
    "    supportsAuthenticatedExtendedCard = true,\n",
    "\n",
    "    // Skills/Capabilities\n",
    "    skills = listOf(\n",
    "        AgentSkill(\n",
    "            id = \"joke-generation\",\n",
    "            name = \"Joke Generation\",\n",
    "            description = \"Generate joke based on content\",\n",
    "            tags = listOf(\"joke\"),\n",
    "            examples = listOf(\n",
    "                \"Joke about apple\",\n",
    "            )\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "println(agentCard)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentCard(protocolVersion=0.3.0, name=Joke maker, description=AI agent specialized in telling joke, url=http://localhost:9000/a2a, preferredTransport=TransportProtocol(value=JSONRPC), additionalInterfaces=null, iconUrl=null, provider=null, version=2.1.0, documentationUrl=null, capabilities=AgentCapabilities(streaming=true, pushNotifications=true, stateTransitionHistory=true, extensions=null), securitySchemes={}, security=[], defaultInputModes=[text/plain, text/markdown, image/jpeg], defaultOutputModes=[text/plain, text/markdown, application/json], skills=[AgentSkill(id=joke-generation, name=Joke Generation, description=Generate joke based on content, tags=[joke], examples=[Joke about apple], inputModes=null, outputModes=null, security=null)], supportsAuthenticatedExtendedCard=true, signatures=null)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Server Initialization and Start\n",
    "\n",
    "This cell initializes and starts the A2A server.\n",
    "\n",
    "1. An `A2AServer` instance is created with the `SimpleJokeAgentExecutor` and the `agentCard`.\n",
    "2. An `HttpJSONRPCServerTransport` is created to handle communication over HTTP.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:23:59.721337Z",
     "start_time": "2025-11-01T12:23:59.664811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Create the A2A server instance\n",
    "val a2aServer = A2AServer(\n",
    "    agentExecutor = SimpleJokeAgentExecutor(),\n",
    "    agentCard = agentCard\n",
    ")\n",
    "\n",
    "// Create the HTTP JSON-RPC transport\n",
    "val transport = HttpJSONRPCServerTransport(a2aServer)\n",
    "val port = 9000\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. The `transport.start()` method starts the server on port 9000, listening on the `/a2a` path.\n",
    "\n",
    "Note: The Kotlin notebook interruption is not working when `wait = true`, thus using `while(true){..}` as a replacement"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:29:35.464960Z",
     "start_time": "2025-11-01T12:29:35.415284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Start the server\n",
    "runBlocking {\n",
    "    println(\"Running a2a server at http://localhost:$port\")\n",
    "    transport.start(\n",
    "        agentCard = agentCard,\n",
    "        engineFactory = CIO,           // Ktor engine (CIO, Netty, Jetty)\n",
    "        port = port,                   // Server port\n",
    "        path = \"/a2a\",                 // API endpoint path\n",
    "        wait = false                   // Do not block until the server stops, setting true will not work in Kotlin Notebook interruption\n",
    "    )\n",
    "    println(\"Server started. Remeber to stop the server using the following cell or use restart the whole kernel\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a2a server at http://localhost:9000\n",
      "Server started. Remeber to stop the server using the following cell or use restart the whole kernel\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stop the Server\n",
    "\n",
    "This cell stops the A2A server. It's important to run this cell when you are finished to release the port."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T12:29:41.220366Z",
     "start_time": "2025-11-01T12:29:41.173958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// Stop the server\n",
    "runBlocking {\n",
    "    println(\"Stopping a2a server at http://localhost:$port\")\n",
    "    transport.stop()\n",
    "    println(\"Stopped\")\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping a2a server at http://localhost:9000\n",
      "Stopped\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-Beta2",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
