{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Running LLM inference with Spring AI & Ollama\n",
    "This notebook implement the basic text-to-text generation using [Spring AI](https://spring.io/projects/spring-ai) and Ollama.\n",
    "You need to install Ollama in your machine in order to run.\n",
    "\n",
    "Free feel to contribute to add more use cases.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install dependencies"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T14:04:51.345849Z",
     "start_time": "2025-01-12T14:04:51.295287Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "// load version variables\n",
    "%use @file[resources/version.json](currentDir=\".\")"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T14:04:53.069959Z",
     "start_time": "2025-01-12T14:04:52.864835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE {\n",
    "    repositories {\n",
    "        maven { url = \"https://repo.spring.io/milestone\" }\n",
    "        mavenCentral()\n",
    "    }\n",
    "    dependencies {\n",
    "        implementation(\"org.springframework.ai:spring-ai-core:$springAiVersion\")\n",
    "        implementation(\"org.springframework.ai:spring-ai-ollama:$springAiVersion\")\n",
    "\n",
    "        implementation(\"io.projectreactor:reactor-core:$reactorVersion\")\n",
    "        implementation(\"org.jetbrains.kotlinx:kotlinx-coroutines-core-jvm:$kotlinCoroutineVersion\")\n",
    "        implementation(\"org.jetbrains.kotlinx:kotlinx-coroutines-reactor:$kotlinCoroutineVersion\")\n",
    "        implementation(\"org.jetbrains.kotlinx:kotlinx-coroutines-reactive:$kotlinCoroutineVersion\")\n",
    "    }\n",
    "    import(\n",
    "        \"kotlinx.coroutines.*\",\n",
    "        \"kotlinx.coroutines.flow.*\",\n",
    "        \"kotlinx.coroutines.reactor.*\",\n",
    "        \"kotlinx.coroutines.reactive.*\",\n",
    "    )\n",
    "}\n",
    "\n",
    "// list the library, if the dependencies doesn't show up, run again and restart the kernel\n",
    "notebook.currentClasspath.joinToString(\"\\n\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/kotlin-stdlib-1.9.23.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/kotlin-reflect-1.9.23.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/kotlinx-serialization-core-jvm-1.6.3.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/annotations-13.0.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/slf4j-api-2.0.12.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/api-0.12.0-356.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/kotlinx-serialization-json-jvm-1.6.3.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/kotlin-script-runtime-1.9.23.jar\n",
       "/Users/gaplo917/Library/Caches/JetBrains/IntelliJIdea2024.3/kotlinNotebook/kotlin-notebook-standalone.eb20de96/kernels/0.12.0-356/kotlin-jupyter-script-classpath-shadowed-zip_extracted/lib-0.12.0-356.jar\n",
       "/Users/gaplo917/.m2/repository/io/projectreactor/reactor-core/3.7.1/reactor-core-3.7.1.jar\n",
       "/Users/gaplo917/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar\n",
       "/Users/gaplo917/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.9.0/kotlinx-coroutines-core-jvm-1.9.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/jetbrains/annotations/23.0.0/annotations-23.0.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/2.0.0/kotlin-stdlib-2.0.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-reactive/1.9.0/kotlinx-coroutines-reactive-1.9.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-reactor/1.9.0/kotlinx-coroutines-reactor-1.9.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/ai/spring-ai-core/1.0.0-M5/spring-ai-core-1.0.0-M5.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/jackson/module/jackson-module-jsonSchema/2.17.2/jackson-module-jsonSchema-2.17.2.jar\n",
       "/Users/gaplo917/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.17.2/jackson-annotations-2.17.2.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.17.2/jackson-core-2.17.2.jar\n",
       "/Users/gaplo917/.m2/repository/io/swagger/core/v3/swagger-annotations/2.2.20/swagger-annotations-2.2.20.jar\n",
       "/Users/gaplo917/.m2/repository/com/github/victools/jsonschema-module-swagger-2/4.35.0/jsonschema-module-swagger-2-4.35.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/slf4j/slf4j-api/2.0.3/slf4j-api-2.0.3.jar\n",
       "/Users/gaplo917/.m2/repository/org/antlr/ST4/4.3.4/ST4-4.3.4.jar\n",
       "/Users/gaplo917/.m2/repository/org/antlr/antlr-runtime/3.5.3/antlr-runtime-3.5.3.jar\n",
       "/Users/gaplo917/.m2/repository/org/antlr/antlr4-runtime/4.13.1/antlr4-runtime-4.13.1.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-context/6.1.15/spring-context-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-aop/6.1.15/spring-aop-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-beans/6.1.15/spring-beans-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-core/6.1.15/spring-core-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-jcl/6.1.15/spring-jcl-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-expression/6.1.15/spring-expression-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/io/micrometer/micrometer-observation/1.12.12/micrometer-observation-1.12.12.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-messaging/6.1.15/spring-messaging-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/io/micrometer/micrometer-core/1.13.8/micrometer-core-1.13.8.jar\n",
       "/Users/gaplo917/.m2/repository/io/micrometer/micrometer-commons/1.13.8/micrometer-commons-1.13.8.jar\n",
       "/Users/gaplo917/.m2/repository/org/hdrhistogram/HdrHistogram/2.2.2/HdrHistogram-2.2.2.jar\n",
       "/Users/gaplo917/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar\n",
       "/Users/gaplo917/.m2/repository/io/micrometer/context-propagation/1.1.2/context-propagation-1.1.2.jar\n",
       "/Users/gaplo917/.m2/repository/com/knuddels/jtokkit/1.1.0/jtokkit-1.1.0.jar\n",
       "/Users/gaplo917/.m2/repository/com/github/victools/jsonschema-generator/4.35.0/jsonschema-generator-4.35.0.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/classmate/1.5.1/classmate-1.5.1.jar\n",
       "/Users/gaplo917/.m2/repository/com/github/victools/jsonschema-module-jackson/4.35.0/jsonschema-module-jackson-4.35.0.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.1/jackson-databind-2.16.1.jar\n",
       "/Users/gaplo917/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.1/jackson-datatype-jsr310-2.16.1.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/ai/spring-ai-ollama/1.0.0-M5/spring-ai-ollama-1.0.0-M5.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/ai/spring-ai-retry/1.0.0-M5/spring-ai-retry-1.0.0-M5.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/retry/spring-retry/2.0.9/spring-retry-2.0.9.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-webflux/6.1.15/spring-webflux-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-web/6.1.15/spring-web-6.1.15.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.3.6/spring-boot-starter-logging-3.3.6.jar\n",
       "/Users/gaplo917/.m2/repository/ch/qos/logback/logback-classic/1.5.12/logback-classic-1.5.12.jar\n",
       "/Users/gaplo917/.m2/repository/ch/qos/logback/logback-core/1.5.12/logback-core-1.5.12.jar\n",
       "/Users/gaplo917/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.23.1/log4j-to-slf4j-2.23.1.jar\n",
       "/Users/gaplo917/.m2/repository/org/apache/logging/log4j/log4j-api/2.23.1/log4j-api-2.23.1.jar\n",
       "/Users/gaplo917/.m2/repository/org/slf4j/jul-to-slf4j/2.0.16/jul-to-slf4j-2.0.16.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/ai/spring-ai-openai/1.0.0-M5/spring-ai-openai-1.0.0-M5.jar\n",
       "/Users/gaplo917/.m2/repository/io/rest-assured/json-path/5.4.0/json-path-5.4.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/apache/groovy/groovy-json/4.0.16/groovy-json-4.0.16.jar\n",
       "/Users/gaplo917/.m2/repository/org/apache/groovy/groovy/4.0.16/groovy-4.0.16.jar\n",
       "/Users/gaplo917/.m2/repository/io/rest-assured/rest-assured-common/5.4.0/rest-assured-common-5.4.0.jar\n",
       "/Users/gaplo917/.m2/repository/org/apache/commons/commons-lang3/3.11/commons-lang3-3.11.jar\n",
       "/Users/gaplo917/.m2/repository/org/springframework/spring-context-support/6.1.15/spring-context-support-6.1.15.jar"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Function to measure model performance\n",
    "A sample implementation using stream to measure key metrics\n",
    "- time to first token\n",
    "- input token process rate/s\n",
    "- output token process rate/s"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T13:49:04.166581Z",
     "start_time": "2025-01-12T13:49:03.758032Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "import org.springframework.ai.chat.model.ChatModel\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "import kotlin.time.measureTimedValue\n",
    "\n",
    "data class ModelPerformance(\n",
    "    val timeToFirstTokenInMills: Double,\n",
    "    val totalTimeInMills: Double,\n",
    "    val promptTokens: Long,\n",
    "    val generationTokens: Long,\n",
    "    val inputTokenRatePerSec: Double,\n",
    "    val outputTokenRatePerSec: Double\n",
    ")\n",
    "\n",
    "fun ChatModel.measureModelPerformance(prompt: Prompt = Prompt(\"tell me 5 jokes\")): ModelPerformance {\n",
    "    var ttft: Long? = null\n",
    "\n",
    "    val timedResp = measureTimedValue {\n",
    "        runBlocking {\n",
    "            val startTime = System.nanoTime()\n",
    "            stream(prompt)\n",
    "                .asFlow()\n",
    "                .onStart {\n",
    "                    ttft = System.nanoTime() - startTime\n",
    "                }\n",
    "                .onEach {\n",
    "                    print(it.result?.output?.content)\n",
    "                }\n",
    "                .last()\n",
    "        }\n",
    "    }\n",
    "    val resp = timedResp.value\n",
    "    val totalTime = timedResp.duration.inWholeMilliseconds\n",
    "    val timeToFirstTokenInMills = ttft!! / 1_000_000.0\n",
    "    return ModelPerformance(\n",
    "        timeToFirstTokenInMills = timeToFirstTokenInMills,\n",
    "        totalTimeInMills = timedResp.duration.inWholeMilliseconds.toDouble(),\n",
    "        promptTokens = resp.metadata.usage.promptTokens,\n",
    "        generationTokens = resp.metadata.usage.generationTokens,\n",
    "        inputTokenRatePerSec = resp.metadata.usage.promptTokens * 1000.0 / timeToFirstTokenInMills,\n",
    "        outputTokenRatePerSec = resp.metadata.usage.generationTokens * 1000.0 / (totalTime - timeToFirstTokenInMills)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create Ollama Gemma2 2B INT4 model\n",
    "You need approximately 2GB GPU VRAM to run `gemma2:2b` locally."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T09:01:49.140425Z",
     "start_time": "2025-01-12T09:01:47.127461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "import org.springframework.ai.ollama.OllamaChatModel\n",
    "import org.springframework.ai.ollama.api.OllamaApi\n",
    "import org.springframework.ai.ollama.api.OllamaOptions\n",
    "\n",
    "val model = OllamaChatModel.builder()\n",
    "    .ollamaApi(OllamaApi(\"http://localhost:11434\"))\n",
    "    .defaultOptions(\n",
    "        OllamaOptions.builder()\n",
    "            .model(\"gemma2:2b\")\n",
    "            .numCtx(8192)\n",
    "            .temperature(0.7)\n",
    "            .build()\n",
    "    ).build()\n",
    "\n",
    "model.measureModelPerformance(Prompt(\"tell me 5 jokes\"))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five jokes for you:\n",
      "\n",
      "1. **Why don't scientists trust atoms?**  Because they make up everything!\n",
      "2. **What do you call a lazy kangaroo?** A pouch potato!\n",
      "3. **Why did the scarecrow win an award?** Because he was outstanding in his field! \n",
      "4. **Why don't eggs tell jokes?** They'd crack each other up!\n",
      "5. **What do you get from a pampered cow?** Spoiled milk!\n",
      "\n",
      "\n",
      "Let me know if you want to hear some more! ðŸ˜Š  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelPerformance(timeToFirstTokenInMills=17.103209, totalTimeInMills=1746.0, promptTokens=14, generationTokens=123, inputTokenRatePerSec=818.5598386829045, outputTokenRatePerSec=71.14363369768093)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectLibraries": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
